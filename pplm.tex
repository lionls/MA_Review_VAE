\section{Kontrollierbare Textgeneration von Sprachmodellen}\raggedbottom
Die in Abschnitt \ref{coop} vorgestellte COOP Methode zur Suche der optimalen Kombination von Latentvektoren zur Maximierung des \textit{Input-Output-Overlaps} erzielt beeindruckende Resultate.
COOP verwendet unter anderem das VAE Modell Optimus, welches zur Generation den kombinierten Latentvektor $z$ mittels Decoder $p_\theta(x|z)$ zu einem Text $\hat{x}$ rekonstruiert.
Als alternatives Modell wird BiMeanVAE vorgestellt, welches ein auf LSTM basierender Variational Autoencoder ist.

Es stellt sich die Frage ob diese Latentvektoren als Grundlage verwendet werden können, um durch weitere Optimierungen bessere Ergebnisse erzielen zu können.

Unkontrollierte Sprachmodelle modellieren Texte über die Wahrscheinlichkeit $p(X)$ für eine Sequenz $X=\{x_0,...,x_n\}$.
In Kapitel \ref{transformer} wurde die Funktionsweise von Transformer-Sprachmodellen erklärt. 
Bei der Generation werden die vorherigen Key-Value Paare der Attention-Layer in einer Vergangenheitsmatrix $H_t = [(K_t^{(1)},V_t^{(1)}), \ldots , (K_t^{(n)},V_t^{(n)})]$ gespeichert, wobei $K$ und $V$ die einzelnen Key-, Value-Vektoren im Layer $n$ zum Zeitpunkt $t$ repräsentieren. %history matrix
Diese Vergangenheitsmatrizen werden verwendet, um bei der Generation auf bereits vorher berechnete Key-, Value-Werte zurückgreifen zu können und somit effizienter Text generieren zu können.


Uber hat mit der Einführung von Plug and Play Language Models \citep{DBLP:journals/corr/abs-1912-02164} es ermöglicht, die Textgeneration bei großen Sprachmodellen wie zum Beispiel GPT-2 kontrolliert zu beeinflussen.
Kontrollierbare Generation von Texten mittels Sprachmodellen entspricht dem Modellieren von $p(x|a)$, wobei hier $a$ für ein kontrollierbares Attribut in Bezug auf den generierten Text $x$ ist. 
Mit dem Satz von Bayes lässt sich das kontrollierbare Sprachmodell zu $p(x|a)\propto p(a|x)p(x)$ umformulieren. 
Das Attribut Modell $p(a|x)$ bewertet einen Satz $x$ auf den Besitz eines Attributs $a$ mit einer Wahrscheinlichkeit.


Zur kontrollierbaren Generation werden bei PPLM-Modellen Gradienten für die generierten Sequenzen über die Log-Likelihood des normalen Sprachmodells $log(p(x))$ und der Log-Likelihood des Attribut-Modells $log(p(a|x))$ in Bezug auf die Vergangenheitsmatrix errechnet. 
Durch Veränderung der Vergangenheitsmatrix $\tilde{H}_t = (H_t+\Delta H_t)$ wird die Wahrscheinlichkeit das nächste Token mit den gewünschten Attributen zu erhalten erhöht. Hierbei wird $\Delta H_t$ Schrittweise durch den Gradienten des Attribut-Modells errechnet und mit Null initialisiert.
Um den Gradienten des Attribut-Modells bestimmen können wird dieses zu $p(a|H_t+\Delta H_t)$ umformuliert.
\begin{align*}
\Delta H_t \leftarrow \Delta H_t + \alpha \frac{\nabla_{\Delta H_t} \text{log }p(a|H_t+\Delta H_t)}{\| \nabla_{\Delta H_t} \text{log }p(a|H_t+\Delta H_t)\|^\gamma}
\end{align*}
In der Gleichung gibt $\alpha$ die Schrittgröße und $\gamma$ die Skalierung der Normalisierung an. 
Die Iteration kann mehrmals hintereinander ausgeführt werden.

Die so durch die modifizierte Vergangenheitsmatrix $\tilde{H}_t$ berechnete Ausgangsverteilung $\tilde{p}_{t+1}$ wird mit der nicht modifizierten Ausgangsverteilung $p_{t+1}$ kombiniert, um den generierten Text ebenfalls durch die Sprachmodell-Verteilung zu beeinflussen.
Somit wird der nächste Token wie folgt gesamplet: $\hat{x}_{t+1} \sim \frac{1}{\beta} (\tilde{p}_{t+1}^{\text{ }\gamma} \cdot p_{t+1}^{1-\gamma})$.
Durch Veränderung von $\gamma$ lässt sich der Einfluss des unmodifizierten Sprachmodells auf die Ausgabe festlegen. Hier konvergiert bei $\gamma \rightarrow 1$ die Ausgabe zur Verteilung des modifizierten Sprachmodells und $\gamma \rightarrow 0$ gegen die Ausgabe des unmodifizierten Sprachmodells.
\subsection{Verbessern der Textgeneration von Optimus}
Den Variational Autoencoder Optimus mit einem Attributions-Modell zu kombinieren ist aufgrund der Injektion des Latentvektors schwierig.
Optimus kann bereits unter Einbezug des Latentvektors Texte kontrolliert generieren $p(x|z)$.
Die Berücksichtigung eines Attribut-Models bei der Generierung des Textes entspricht $p(x|a,z) \propto p(a|x,z)p(x|z)$.%)= \frac{p(a|x,z)p(x|z)}{p(a|z)}$. %MATH WRONG
Da der Latentvektor $z$ in die Vergangenheitsmatrix $H_t$ injeziert wird, wird der Latentvektor direkt optimiert und $\Delta z$ ergibt sich durch folgende Iteration:
\begin{align*}
    \Delta z \leftarrow \Delta z + \alpha \frac{\nabla_{\Delta z} \text{log }p(a|z+\Delta z,z)}{\| \nabla_{\Delta z} \text{log }p(a|z+\Delta z,z)\|^\gamma}
\end{align*}

%KL_LOSS


\subsection{Verbessern der Textgeneration von BiMeanVAE}
\textsc{BiMeanVAE} ist ein Variational Autoencoder bestehend aus einem bidirektionalem LSTM Encoder gepaart mit einem LSTM Decoder.
Der LSTM Decoder erhält als Eingabe den Latentvektor $z$ und den berechneten Hiddenstate $h_t$ und Cellstate $c_t$.
Um diesen LSTM Decoder mit einem Attributmodel zu optimieren bieten sich 3 unterschiedliche Ansätze:
\begin{enumerate}
    \item Optimieren über den Latentvektor $z$
    \item Optimieren des vorherigen Hiddenstates $h_t$ vor der nächsten Berechnung
    \item Optimieren des vorherigen Cellstates $c_t$ vor der nächsten Berechnung
\end{enumerate}

Es ist möglich zu allen drei Optionen einen Gradienten zur Veränderung der entsprechenden Variabel zu bestimmen. Die gewählte Schrittgröße ist $\alpha = 0.1$.
Nachfolgend wurden alle drei Optionen auf dem Amazon Datensatz evaluiert, um die zu optimierende Variabel mit der bestmöglichen Performance zu finden.
Bei der Selektion der Ausgabebewertung wurde die Bewertung ausgewählt, die die höchste ROUGE-1 Übereinstimmung mit den Zusammenfassungsbewertungen hat.
Somit wird stets die bestmögliche generierte Bewertung ausgewählt.

\begin{table}[h!]
    \centering
    \begin{tabular}{@{}llll@{}}
    \toprule
                    Modell   & \multicolumn{3}{c}{Amazon}              \\ \midrule
    \textbf{\textsc{BiMeanVAE}}    & \textbf{R1} & \textbf{R2} & \textbf{RL} \\ \midrule
  %  \textsc{BiMeanVAE} &             &             &             \\
    Baseline        & 39.50       & \underline{8.62}     &  22.79     \\
    $\quad$ optimze $z$        &   \underline{40.04}     &   8.35    &    \textbf{23.64}   \\
    $\quad$ optimze $h_t$      &  39.96   &    8.34  &  22.94  \\
    $\quad$ optimze $c_t$      &  \textbf{40.81}   &     \textbf{8.91}  &   \underline{23.49}    \\ \bottomrule
    \end{tabular}
    \caption{Ergebnisse für die Optimierung der unterschiedlichen Variablen $z,h_t,c_t$ über ein Attributionsmodell}
    \label{opt_bimeanvae}
\end{table}

In Tabelle \ref{opt_bimeanvae} sind die ROUGE-Scores, welche in Abschnitt \ref{evalmetric} genauer erklärt werden, für die separiert optimierten Variablen $z, h_t, c_t$ aufgelistet.
Beim Evaluieren der unterschiedlichen Optimierungsversuche zeigt sich, dass jede Optimierung bessere Ergebnisse als die unoptimierte Baseline auf den Gold-Summaries erzielt.
Die größte Leistungssteigerung erzielt eine Optimierung der Variabel $c_t$.
Somit beschreibt folgende Gleichung den Optimierungsschritt $\Delta c_t$ bei \textsc{BiMeanVAE}.
\begin{align*}
    \Delta c_t \leftarrow \Delta c_t + \alpha \frac{\nabla_{\Delta c_t} \text{log }p(a|c_t+\Delta c_t,c_t)}{\| \nabla_{\Delta c_t} \text{log }p(a|c_t +\Delta c_t ,c_t )\|^\gamma}
\end{align*}


\subsection{Bag of Words Attribut-Modell}
Als Attribut Modell wird ein Bag of Words Modell verwendet, welches einen Loss über die Summe der Wahrscheinlichkeiten der einzelnen vorhergesagten Wörter bildet.
Sei $\{w_0, \ldots, w_n\}$ eine Gruppe von Tokens die ein bestimmtes Thema repräsentieren und $p_{t+1}$ die Ausgabeverteilung über die Tokens des Sprachmodells.
Dann ist die Log-Likelihood des Attribut-Modells: 
\begin{align*}
    \text{log }p(a|x) = \text{log }(\sum_{i=0}^n p_{t+1}[w_i])
\end{align*}

Um den \textit{Input-Output-Overlap} zwischen den Eingabereviews und den generierten Reviews zu maximieren wird das Bag of Words Modell erzeugt indem die $k$ am häufigsten vorkommenden Wörter über alle Reviews eines Produktes gewählt werden.
Vor dem auswählen der häufigsten vorkommenden Wörter werden von dieser Menge Stopwörter entfernt.
Die besten Ergebnisse werden mit $k=150$ erzielt. %ÜBERPRÜUFEN 

Des Weiteren können die Bag of Words Tokens gewichtet werden, indem die $k$ häufigsten Wörter nach ihrer Anzahl über eine Softmax-Funktion in eine Wahrscheinlichkeitsverteilung transformiert werden.
Hierdurch erhalten besonders häufig vorkommende Wörter ein höheres Gewicht als weniger häufig vorkommende Wörter.

Die Bag of Words Menge kann auch durch anderweitige Keyword-Extraktion wie zum Beispiel durch YAKE \citep{CAMPOS2020257} generiert werden.


Weiterhin kann die Bag of Words Menge bei der Generierung optimiert werden. 
So können bereits generierte Tokens nach einem Durchlauf aus der Bag of Words Menge entfernt werden, um zum Beispiel bei der Reviewgeneration einen Faktor nicht mehrmalig zu forcieren.


\subsection{Latentvektoroptimisierung mit Beam Search}
Beam Search ist ein Suchalgorithmus zur Auswahl des Ausgabesatzes mit der höchsten Wahrscheinlichkeit. 
Im Gegensatz zur normalen Greedy Search wird beim Beam Search Algorithmus die Gruppe mit den N bestmöglichen Tokens für eine Position ausgewählt. 
Über die Maximierung der bedingten Wahrscheinlichkeit wird final entschieden welche der zuvor ausgewählten Tokens 

\subsection{Moverscore Ranking}
\label{moverscore_ranking}
Der in Abschnitt \ref{moverscore} vorgestellte Moverscore ermöglicht einen semantischen Vergleich von Textsequenzen. 
So kann insbesondere Bewertungen mit anders formulierten Meinungen, die die gleiche Aussage treffen ein hoher Ähnlichkeitswert zugewiesen werden.
Da dem Modell nur die Eingabebewertungen zur Verfügung stehen, ist eine Berechnung des \textit{Input-Output-Overlap} lediglich über den ROUGE-1 Score nicht ausreichend.
Zwischen den Eingabebewertungen und den Gold-Summaries besteht eine hohe semantische Ähnlichkeit, weshalb der Moverscore miteinbezogen wird um ein besseres Ranking der Ausgabewertungen zu erzeugen.
Des Weiteren wird die \textit{Input-Output-Overlap} Funktion dahingehend abgeändert, dass sie ebenfalls die ROUGE-2 und ROUGE-L Scores miteinbezieht.
Somit ergibt sich eine neue Rankingfunktion für die generierten Ausgabebewertungen:
\begin{align*}
    \text{SCORE}(\hat{x_i}) = Input\text{-}Output\text{-}Overlap(\hat{x_i}, \text{InputReviews}) + 2 \cdot Moverscore(\hat{x_i}, \text{InputReviews})
\end{align*}

Mit dieser Rankingfunktion wird bei den einzelnen generierten Reviews nun die semantische Ähnlichkeit mit den Eingabebewertungen miteinbezogen. 
Hierdurch können auch generierte Bewertungen mit weniger überlappenden N-Gramms, aber einer hohen semantischen Ähnlichkeit mit einer höheren Wahrscheinlichkeit ausgewählt werden.

\pagebreak
